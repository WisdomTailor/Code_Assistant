{
  "GPT-4 Turbo (128K)": {
    "model_configuration": {
      "llm_type": "openai",
      "model": "gpt-4-1106-preview",
      "max_model_supported_tokens": 128000,
      "max_model_completion_tokens": 4096
    }
  },
  "GPT 4": {
    "model_configuration": {
      "llm_type": "openai",
      "model": "gpt-4",
      "max_model_supported_tokens": 8192 
    }
  },
  "GPT 4 (32K)": {
    "model_configuration": {
      "llm_type": "openai",
      "model": "gpt-4-32k",
      "max_model_supported_tokens": 32768  
    }
  },
  "GPT 3.5 Turbo (16K)": {
    "model_configuration": {
      "llm_type": "openai",
      "model": "gpt-3.5-turbo-16k",
      "max_model_supported_tokens": 16384
    }
  },
  "GPT 3.5 Turbo": {
    "model_configuration": {
      "llm_type": "openai",
      "model": "gpt-3.5-turbo",
      "max_model_supported_tokens": 4097 
    }
  },
  "LLaMA 2": {
    "model_configuration": {
      "llm_type": "llama2",
      "model": "H:\\LLM\\llama-2-13b-chat.gguf.q5_1.bin",
      "max_model_supported_tokens": 4096
    }
  },
  "WizardCoder-Python 34B (Q4)": {
    "model_configuration": {
      "llm_type": "llama2",
      "model": "H:\\LLM\\wizardcoder-python-34b-v1.0.Q4_K_M.gguf",
      "max_model_supported_tokens": 16384
    }
  },
  "WizardCoder-Python 13B (Q5)": {
    "model_configuration": {
      "llm_type": "llama2",
      "model": "H:\\LLM\\wizardcoder-python-13b-v1.0.Q5_K_M.gguf",
      "max_model_supported_tokens": 16384
    }
  }
}
